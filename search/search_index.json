{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AMBER: Automated annotation and Multimodal Bag Extraction for Robotics","text":"<p>Amber is a ROS2 friendly ML tools. Your rosbag2 become dataset!</p>"},{"location":"#how-it-works","title":"How it works","text":"<ol> <li>Prepare rosbag2 with mcap format.</li> <li>Prepare task description yaml file.</li> <li>Enjyo your ML life with Robots!</li> </ol>"},{"location":"#how-to-setup","title":"How to setup?","text":""},{"location":"#check-your-os-is-suppoted-platform","title":"Check your OS is suppoted platform?","text":"<p>This tool is only support ubuntu 22.04. Please install ubuntu 22.04 in your local machine first.</p>"},{"location":"#install-dependencies","title":"Install Dependencies","text":""},{"location":"#poetry","title":"Poetry","text":"<p>Setup environment and dependencies in python. Please follow this documentation.</p> <p>Warning</p> <p>Developer and github actions are tested under poetry 1.2.0</p>"},{"location":"#docker","title":"Docker","text":"<p>Some automation tools are executed inside docker. Please follow this documentation.</p> <p>Notion</p> <p>Developer use docker version 23.0.5</p>"},{"location":"#nvidia-driver-and-nvidia-dockeroptional","title":"Nvidia driver and nvidia docker(Optional)","text":"<p>Some automation tools support cuda. If you want to use gpu, please install nvidia driver and nvidia docker.</p>"},{"location":"#google-testoptional","title":"Google test(Optional)","text":"<p>Google test is a used for testing C++ code inside amber. It is optional and it is not required for building amber in your local machine.</p> <pre><code>sudo apt update &amp; sudo apt install -y googletest\n</code></pre>"},{"location":"tips/","title":"Tips","text":""},{"location":"tips/#i-do-not-have-rosbag2-but-i-have-rosbag-ros1","title":"I do not have rosbag2, but I have rosbag (ROS1)","text":"<p>This tool can convert your rosbag into rosbag2 very easily.</p>"},{"location":"tips/#my-rosbag-is-not-a-mcap-format","title":"My rosbag is not a mcap format.","text":"<p>You can use <code>ros2 bag convert</code> command. First, you prepare compress.yaml like below.</p> <pre><code>output_bags:\n- uri: rosbag\nstorage_id: mcap\ncompression_mode: message\ncompression_format: zstd\nall: true\ncompression_queue_size: 0\ncompression_threads: 0\n</code></pre> <pre><code>ros2 bag convert -i (PATH_TO_ROSBAG) -o conversion.yaml\n</code></pre>"},{"location":"automation/automation/","title":"Automation","text":"<p>Automation helps you to enjoy your ML life. Automation tools can be used with two ways, use with CLI and use with Python API</p>"},{"location":"automation/automation/#cli-tools","title":"CLI tools","text":"<p>All of the automation tools can be use <code>amber automation</code> command.</p> <pre><code>usage: amber automation [-h] task_description_yaml_path dataset_description_yaml_path rosbag_path\n\npositional arguments:\n  task_description_yaml_path\n                        Path to the yaml description file path\n  dataset_description_yaml_path\n                        Path to the yaml description file path for dataset\n  rosbag_path           Path to the target rosbag path\n\noptions:\n  -h, --help            show this help message and exit\n</code></pre>"},{"location":"automation/automation/#python-api","title":"Python API","text":"<p>All of the automation tools have Python classes. If you want to know detail, please read detatiled documentations.</p>"},{"location":"automation/automation/#support-status","title":"Support status","text":"Name Docker Support CUDA Support(Docker) Native Support CUDA Support(Native) Huggingface Support DeticImageLabaler"},{"location":"automation/automation/#docker-support","title":"Docker Support","text":"<p>Support automation algorithm inside docker.</p>"},{"location":"automation/automation/#native-support","title":"Native Support","text":"<p>Support automation algorithm in native environment.</p>"},{"location":"automation/automation/#hugging-face-support","title":"Hugging face Support","text":"<p>Support running automation algorithum on hugging face.</p>"},{"location":"automation/automation/#cuda-support","title":"CUDA Support","text":"<p>Support cuda for accelerating automation.</p>"},{"location":"automation/detic_image_labaler/","title":"Detic image labaler","text":"<p>Detic is a deep learning algorithum developed by facebook research. This tool generate annotation data by using detic. Detic can classify 21k classes.</p>"},{"location":"automation/detic_image_labaler/#use-with-cli","title":"Use with CLI","text":"<p>Warning</p> <p>This sample command is written with the assumption that it will be executed in the root directory of the amber package.</p> <pre><code>amber automation tests/detic_image_labeler.yaml tests/read_image_ford.yaml tests/rosbag/ford/ford.mcap\n</code></pre> <p>Task description yaml for the detic_image_labaler is here.</p> <pre><code>task_type: detic_image_labeler # This line should be detic_image_labeler\nconfidence_threshold: 0.5      # If the confidence overs the threshold, detic determines the object are exists.\nvideo_output_path: output.mp4  # Relative path to the visualization result.\ndocker_config:                 # Docker configuration\nuse_gpu: false               # If true, run with CUDA\n</code></pre> <p>After executing this command, <code>output.mp4</code> movie file was generated.</p>"},{"location":"automation/detic_image_labaler/#use-with-python-api","title":"Use with Python API","text":"<pre><code>current_path = Path(os.path.dirname(os.path.realpath(__file__)))\nlabeler = DeticImageLabeler(str(current_path / \"detic_image_labeler.yaml\"))\ndataset = Rosbag2Dataset(\n    str(current_path / \"rosbag\" / \"ford\" / \"ford.mcap\"),\n    str(current_path / \"read_image_ford.yaml\"),\n)\nlabeler.inference(dataset)\n</code></pre> <p><code>detic_image_labeler.yaml</code> and <code>read_image_ford.yaml</code> are exactly same when you use detic_image_labaler with CLI.</p> <p>After executing this command, <code>output.mp4</code> movie file was generated.</p>"},{"location":"use_rosbag_as_dataset/how_to_use/","title":"How to use?","text":""},{"location":"use_rosbag_as_dataset/how_to_use/#prepare-rosbag-data","title":"Prepare rosbag data","text":"<p>Warning</p> <p>Currently, some limitations are exists. rosbag2 should be mcap format. only zstd message compression supports.</p>"},{"location":"use_rosbag_as_dataset/how_to_use/#use-rosbag-as-dataset","title":"Use rosbag as dataset","text":"<p>Rosbag includes multimodal data, such as image/pointcloud/audio/etc... So, you need to describe what data you want to extract from rosbag. In order to specify this, write yaml setting file.</p> <pre><code>dataset = Rosbag2Dataset(\"(path to rosbag .mcap file)\", \"(path to rosbag yaml description file)\")\n</code></pre> <p>If you want to know wahat types of task <code>amber</code> supports, please check task description section in this document.</p>"},{"location":"use_rosbag_as_dataset/task_description/read_images/","title":"Read Images","text":"<p>In image_only task, Rosbag2Dataset Class provides only image data. Example task description yaml file is here.</p> <pre><code>dataset_type: image_only\nimage_topics:\n- topic_name: /wamv/sensors/cameras/front_left_camera_sensor/image_raw\ncompressed: true\n- topic_name: /wamv/sensors/cameras/front_right_camera_sensor/image_raw\n</code></pre>"}]}